{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a demo for testing and training PsiDONet. Please refer to README for more information about installation and files organization.**\n",
    "\n",
    "**@author: Mathilde Galinier (megalinier@gmail.com)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./fundamental_functions') \n",
    "\n",
    "import os\n",
    "from auxiliary_functions import create_path_save_name\n",
    "from Train_Test_PsiDONet import train, test\n",
    "from tools import compute_quality_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Train conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_angle      = 30\n",
    "step_angle         = 1\n",
    "size_image         = 128\n",
    "mu                 = 0.000002\n",
    "L                  = 5\n",
    "train_conditions   = [missing_angle, step_angle, size_image, mu, L]\n",
    "dataset            = 'Ellipses'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Choice of the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unrolling    = 'PSIDONetF'        # 'PSIDONetF' or 'PSIDONetFplus' or 'PSIDONetO' or 'PSIDONetOplus'\n",
    "learning_rate      = 0.005\n",
    "nb_epochs          = 3\n",
    "minibatch_size     = 25\n",
    "loss_type          ='MSE'               # 'MSE' or 'SSIM' \n",
    "loss_domain        ='WAV'               # 'WAV' or 'IM'   \n",
    "nb_unrolledBlocks  = 40\n",
    "nb_repetBlock      = 3\n",
    "filter_size        = size_image//4            \n",
    "wavelet_type       ='haar'              # 'haar' or 'db2'\n",
    "level_decomp       = 3\n",
    "precision_float    = 32\n",
    "size_val_limit     = 4*minibatch_size        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Definition of the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optionalText       = ''\n",
    "path_main          = os.path.join('.')\n",
    "path_save          = os.path.join(path_main,'Tensorflow','Results',\\\n",
    "                        create_path_save_name(train_conditions, optionalText, model_unrolling,\n",
    "                                learning_rate, nb_epochs, minibatch_size, loss_type, loss_domain,\n",
    "                                nb_unrolledBlocks, nb_repetBlock, filter_size, \n",
    "                                wavelet_type, level_decomp, precision_float, dataset))\n",
    "path_datasets      = os.path.join(path_main,dataset + '_Datasets','Size_'+str(size_image))\n",
    "paths              = [path_main, path_datasets, path_save]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_conditions=train_conditions,\\\n",
    "        folders=paths,\\\n",
    "        model_unrolling=model_unrolling,\\\n",
    "        lr=learning_rate,\\\n",
    "        nb_epochs=nb_epochs,\\\n",
    "        minibatch_size=minibatch_size,\\\n",
    "        loss_type=loss_type,\\\n",
    "        loss_domain=loss_domain,\\\n",
    "        nb_unrolledBlocks=nb_unrolledBlocks,\\\n",
    "        nb_repetBlock=nb_repetBlock,\\\n",
    "        filter_size=filter_size,\\\n",
    "        wavelet_type=wavelet_type,\\\n",
    "        level_decomp=level_decomp,\\\n",
    "        precision_float=precision_float,\\\n",
    "        size_val_limit=size_val_limit,\\\n",
    "        dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Path to model to restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_restore = os.path.join(path_save,'parameters','MinOnVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(train_conditions=train_conditions,\\\n",
    "        folders=paths,\\\n",
    "        model_unrolling=model_unrolling,\\\n",
    "        minibatch_size=minibatch_size,\\\n",
    "        nb_unrolledBlocks=nb_unrolledBlocks,\\\n",
    "        nb_repetBlock=nb_repetBlock,\\\n",
    "        filter_size=filter_size,\\\n",
    "        wavelet_type=wavelet_type,\\\n",
    "        level_decomp=level_decomp,\\\n",
    "        precision_float=precision_float,\\\n",
    "        dataset=dataset, \\\n",
    "        path_to_restore = path_to_restore)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Show results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compute quality assessment on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('Evaluating the results on test set...')\n",
    "relative_err_mean, MSE_mean, SSIM_mean, PSNR_mean, HaarPSI_mean \\\n",
    "= compute_quality_results(os.path.join(path_datasets, 'val','Images'),os.path.join(path_save,'valset_restoredImages'),precision_float)\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compute quality assessment on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('Evaluating the results on test set...')\n",
    "relative_err_mean, MSE_mean, SSIM_mean, PSNR_mean, HaarPSI_mean \\\n",
    "= compute_quality_results(os.path.join(path_datasets, 'test','Images'),os.path.join(path_save,'testset_restoredImages'),precision_float)\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import iradon\n",
    "from tools import compute_angles\n",
    "import scipy.io as sio\n",
    "\n",
    "# choose an image \n",
    "num = 10556\n",
    "\n",
    "# Paths \n",
    "angles              = compute_angles(missing_angle, step_angle)\n",
    "path_im_groundtruth = os.path.join(path_datasets,'test','Images','im_reduced_'+str(size_image)+'x'+str(size_image)+'_'+str(num)+'.mat')\n",
    "path_sino           = os.path.join(path_datasets, 'test','Sinograms','sino_angles_0_1_179_'+str(num)+'.mat')\n",
    "path_im_restored    = os.path.join(path_save,'testset_restoredImages','im_reduced_'+str(size_image)+'x'+str(size_image)+'_'+str(num)+'.mat')\n",
    "\n",
    "# Load images\n",
    "im_groundtruth = sio.loadmat(path_im_groundtruth)['im_reduced']\n",
    "sino           = sio.loadmat(path_sino)['mnc'][:,angles]\n",
    "im_fbp         = iradon(sino, theta=angles, circle=False)[1:-1,1:-1]\n",
    "im_restored    = sio.loadmat(path_im_restored)['image']\n",
    "\n",
    "# Compute relative errors\n",
    "err_fbp        = np.linalg.norm(im_fbp-im_groundtruth)/np.linalg.norm(im_groundtruth)\n",
    "err_restored   = np.linalg.norm(im_restored-im_groundtruth)/np.linalg.norm(im_groundtruth)\n",
    "\n",
    "# Plot\n",
    "plt.figure(1,figsize=(10, 10))\n",
    "#\n",
    "plt.subplot(131)\n",
    "plt.imshow(im_groundtruth)\n",
    "plt.axis('off')\n",
    "plt.title('Groundtruth')\n",
    "#\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.clip(im_fbp,0,1))\n",
    "plt.axis('off')\n",
    "plt.title('FBP, RE: %.3f'%(err_fbp))\n",
    "#\n",
    "plt.subplot(133)\n",
    "plt.imshow(im_restored)\n",
    "plt.axis('off')\n",
    "plt.title('Restored: RE: %.3f'%(err_restored))\n",
    "#\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
